---
abbrlink: ''
categories: []
date: '2023-12-03T16:45:57.524274+08:00'
tags: []
title: HMM（隐性马尔可夫模型）学习
updated: 2023-12-3T17:11:55.433+8:0
---
HMM隐性马尔可夫模型

和以前学过的状态机有点像

# **1.抽象理解HMM**

用李琳山教授的例子来抽象一个HMM：假设现在面前有三个盒子(A,B,C)，每个盒子里有不同分布的红、蓝、绿球，现在我们背过身去，不看盒子，由另一个人从这些盒子中随机抽取n个球，于是我们得到了一个序列：红、蓝、蓝、红、绿、红、蓝......

这个过程中，我们只知道拿到了哪些球，而不知道另一个人是从哪个盒子里拿出的哪个球，这叫做隐性

假设拿球人第一次是从盒子A中拿球，拿完一个球后，还在A盒拿球的概率为qaa，去B盒拿第二个球的概率为qab、去C盒拿第二个球的概率为qac，以此类推，得到马尔科夫链(借用了李琳山老师的图，图里用了准确的概率，qaa = 0.6，qab=0.3，qac=0.1，以此类推)：

![https://s2.loli.net/2023/12/03/kpyqUAZs7mLGISv.png](https://s2.loli.net/2023/12/03/kpyqUAZs7mLGISv.png)

若在A盒拿到红、绿、蓝球的几率分别为qa1、qa2、qa3，B盒为qb1、qb2、qb3，C盒为qc1、qc2、qc3，就意味着我们可以计算出所有的概率，推断出哪个球来自于哪个盒子的概率最高，最终取概率最高的为取盒子的顺序


# **2.具体定义**

对于HMM模型，首先我们假设I是所有可能的隐藏状态的集合，O是所有可能的观测状态的集合

![](https://pic4.zhimg.com/80/v2-75f8776c6c70e3b775ceacaa3b865fb3_720w.webp)

对于我们之前的例子来说，盒子的顺序就是隐藏状态集合，球的顺序就是观测状态的集合

为了简化计算，做出两个假设：

```
1.每一个隐藏状态只依赖于上一个隐藏状态，即你抽哪个盒子只由上一次抽的盒子决定

2.观测状态只由当前的隐藏状态决定，即抽球时只从当前盒子里抽，不受其他盒子影响
```

因此我们得到状态转移矩阵(以之前的例子，决定下一个盒子是哪个)：

![https://s2.loli.net/2023/12/03/VI8PtKFrqUxSdX7.png](https://s2.loli.net/2023/12/03/VI8PtKFrqUxSdX7.png)

观测状态概率矩阵(决定抽中哪个球)：

![https://s2.loli.net/2023/12/03/9rfTZ2nEW8aXQYb.png](https://s2.loli.net/2023/12/03/9rfTZ2nEW8aXQYb.png)

再增加一个序列长度T，一个初始状态Π = (q1，q2，q3)表示第一次抽中哪个盒子，我们就得到了一个马尔可夫模型

具体推算过程：

1.首先由初始状态得到隐藏状态i1，即第一个盒子是哪个

2.由隐藏状态i1得到观测状态o1，即第一个球是哪个

3.由隐藏状态i1得到隐藏状态i2，即第二个盒子是哪个

4.重复2~3步，直到得到T个观测状态o，所有o组成观测序列Q，即所有拿出来的球


# **3.HMM的三个问题**

评估观察序列概率：已知模型λ=(A,B,π)和观测序列Q，求观测序列出现的概率

预测问题(解码问题)：已知模型λ=(A,B,π)和观测序列Q，求可能的隐藏序列

模型参数学习问题：已知观测序列Q，求模型的参数

## 3.1 评估问题

### 3.1.1. 暴力解法

最简单的，暴力解法，就和上面例子的一样，一路推过去就能把概率全部算出来，但是对于数据很多的时候就要算很久

### 3.1.2.前向算法(Forward Algorithm)

定义在模型λ=(A,B,π)条件下，t时刻时隐藏状态为 qi ，观测状态的序列为 o1,o2,...,ot的概率为前向概率。记为：

![](https://pic4.zhimg.com/80/v2-dfe813f2da82670c1301a5f6853454f3_720w.webp)

若我们知道t时刻所有隐藏状态q的前向概率，则可以推出t+1时刻的前向概率：

![https://s2.loli.net/2023/12/03/9OsMIuygtE1Qwcx.png](https://s2.loli.net/2023/12/03/9OsMIuygtE1Qwcx.png)
